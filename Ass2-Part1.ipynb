{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCS2673 Assignment 2 P1A - Is or is not cancer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#with zipfile.ZipFile('./Image_classification_data.zip', 'r') as zip_ref:\n",
    "#   zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "Split data into train, validation, and test\n",
    "Note that images for the same patient may contain a mix of cancerous and non-cancerous data.\n",
    "Q - Sould we split on patient or just randomly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData = pd.read_csv('./data_labels_mainData.csv')\n",
    "extraData = pd.read_csv('./data_labels_extraData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData = mainData.sample(2000)\n",
    "#mainData = mainData.append(extraData, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratary Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstanceID       int64\n",
      "patientID        int64\n",
      "ImageName       object\n",
      "cellTypeName    object\n",
      "cellType         int64\n",
      "isCancerous      int64\n",
      "dtype: object\n",
      "         InstanceID    patientID     cellType  isCancerous\n",
      "count   2000.000000  2000.000000  2000.000000  2000.000000\n",
      "mean   10146.422000    29.585000     1.519500     0.421500\n",
      "std     6615.368809    17.287689     0.969066     0.493923\n",
      "min        8.000000     1.000000     0.000000     0.000000\n",
      "25%     4108.250000    14.000000     1.000000     0.000000\n",
      "50%     9213.000000    26.000000     2.000000     0.000000\n",
      "75%    16736.750000    46.000000     2.000000     1.000000\n",
      "max    22442.000000    60.000000     3.000000     1.000000\n"
     ]
    }
   ],
   "source": [
    "print(mainData.dtypes)\n",
    "#print(mainData.shape)\n",
    "#print(mainData.info())\n",
    "print(mainData.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Categorical Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData['cellType'] = mainData['cellType'].astype('category')\n",
    "mainData['cellTypeName'] = mainData['cellTypeName'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mainData.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData.drop(['InstanceID'], axis=1,inplace=True)\n",
    "mainData.drop(['cellType'], axis=1,inplace=True)\n",
    "mainData.drop(['cellTypeName'], axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData['isCancerous'] = mainData['isCancerous'].astype('category')\n",
    "\n",
    "#mainData['cellTypeName'] = mainData['cellTypeName'].astype('category')\n",
    "#mainData['cellType'] = mainData['cellType'].astype('category')\n",
    "\n",
    "#? One hot encode cellType?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 8946 to 7832\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   patientID    2000 non-null   int64   \n",
      " 1   ImageName    2000 non-null   object  \n",
      " 2   isCancerous  2000 non-null   category\n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 48.9+ KB\n"
     ]
    }
   ],
   "source": [
    "mainData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patientID      0\n",
       "ImageName      0\n",
       "isCancerous    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i, col in enumerate(mainData.columns):\n",
    "#    print(\"==>\", col)\n",
    "#    print(mainData[col].value_counts())\n",
    "#    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Data:\n",
      "    Total: 2000\n",
      "    Positive: 843 (42.15% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg, pos = np.bincount(mainData.isCancerous)\n",
    "total = neg + pos\n",
    "print('Class Data:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key observations:\n",
    "* Data has 20280  observations and 6 columns.\n",
    "* InstanceID - is Id field, need to remove as not valueable classification attribute\n",
    "* cellTypeName, cellType - indicator of actual cell type and not used in this case for cancer diagnosis\n",
    "* isCancerous - indicator of the actual diagnosis (1 = cancerous, 0 = benign)\n",
    "\n",
    "Split of benign to cancerous is a 35% cancerous, 65% benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check all image files exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20280\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "image_list = set()\n",
    "for filepath in glob.glob('./patch_images/*', recursive=True): #assuming gif\n",
    "    filename = filepath.split(\"\\\\\")[-1]\n",
    "    image_list.add(filename)\n",
    "    \n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Split on Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add classification class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData['isCancerous'] = mainData['isCancerous'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Validate/Test\n",
    "For test and training data split via person.\n",
    "- Check if a person has cancer or not, then would the images for that person have cancer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of patients and observation counts\n",
    "TEST_RATIO = 0.10\n",
    "VAL_RATIO = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split train tests by ratios\n",
    "# Select random patients until the number of images for \n",
    "# each patient sums to the number of records require\n",
    "\n",
    "np.random.seed(43) # Consistent random list\n",
    "\n",
    "recCount = mainData.shape[0]\n",
    "custRec = mainData.patientID.value_counts().to_dict()\n",
    "    \n",
    "patientIds = list(custRec.keys())\n",
    "\n",
    "# Loop through selecting a patient at random summing the number of images they have\n",
    "# until the count of images crosses is more than required number\n",
    "\n",
    "testCust = []\n",
    "testRecs = 0\n",
    "while (testRecs < (recCount * TEST_RATIO)):\n",
    "    pId = np.random.choice(patientIds)\n",
    "    ic = custRec.get(pId)\n",
    "    patientIds.remove(pId)\n",
    "    testCust.append(pId)\n",
    "    testRecs += ic\n",
    "    \n",
    "#print(testCust, testRecs)\n",
    "\n",
    "valCust = []\n",
    "valRecs = 0\n",
    "while (valRecs < (recCount * VAL_RATIO)):\n",
    "    pId = np.random.choice(patientIds)\n",
    "    ic = custRec.get(pId)\n",
    "    patientIds.remove(pId)\n",
    "    valCust.append(pId)\n",
    "    valRecs += ic\n",
    "\n",
    "#print(valCust, valRecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData = mainData[mainData.patientID.isin(testCust)]\n",
    "valData = mainData[mainData.patientID.isin(valCust)]\n",
    "trainData = mainData[~(mainData.patientID.isin(valCust + testCust))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : 1445, Val Data: 332, Test Data: 223\n"
     ]
    }
   ],
   "source": [
    "#print(trainData.shape[0] + valData.shape[0] + testData.shape[0])\n",
    "#print(mainData.shape[0])\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(trainData.shape[0], valData.shape[0], testData.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientID</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>isCancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>39</td>\n",
       "      <td>16473.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>18</td>\n",
       "      <td>8516.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>4</td>\n",
       "      <td>18591.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>22424.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>7</td>\n",
       "      <td>9051.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patientID  ImageName isCancerous\n",
       "6228         39  16473.png           0\n",
       "3240         18   8516.png           1\n",
       "190           4  18591.png           0\n",
       "18            1  22424.png           0\n",
       "750           7   9051.png           0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1], <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(\n",
    "    trainData.isCancerous.value_counts().index.astype(str), \n",
    "    trainData.isCancerous.value_counts().values/np.sum(trainData.isCancerous.value_counts().values), \n",
    "    alpha=0.3, \n",
    "    color='r')\n",
    "plt.bar(\n",
    "    valData.isCancerous.value_counts().index.astype(str), \n",
    "    valData.isCancerous.value_counts().values/np.sum(valData.isCancerous.value_counts().values), \n",
    "    alpha=0.3, \n",
    "    color='b')\n",
    "plt.bar(\n",
    "    testData.isCancerous.value_counts().index.astype(str), \n",
    "    testData.isCancerous.value_counts().values/np.sum(testData.isCancerous.value_counts().values), \n",
    "    alpha=0.3, \n",
    "    color='g')\n",
    "plt.title('isCancerous - Train vs Test')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n",
    "27x27 RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1445 validated image filenames belonging to 2 classes.\n",
      "Found 332 validated image filenames belonging to 2 classes.\n",
      "Found 223 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=trainData,\n",
    "        directory='./patch_images',\n",
    "        x_col=\"ImageName\",\n",
    "        y_col=\"isCancerous\",\n",
    "        target_size=(27, 27),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=valData,\n",
    "        directory='patch_images',\n",
    "        x_col=\"ImageName\",\n",
    "        y_col=\"isCancerous\",\n",
    "        target_size=(27, 27),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=testData,\n",
    "        directory='patch_images',\n",
    "        x_col=\"ImageName\",\n",
    "        y_col=\"isCancerous\",\n",
    "        target_size=(27, 27),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PlotModelFitHistory(mh):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(mh.history['loss'], 'r--')\n",
    "    plt.plot(mh.history['val_loss'], 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(mh.history['binary_accuracy'], 'r--')\n",
    "    plt.plot(mh.history['val_binary_accuracy'], 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PlotConfusionMatrix(test, pred):\n",
    "    cm = confusion_matrix(test, test)\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sn.heatmap(cm, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure \n",
    "As this is a screening task, the impact of a false negative is high (ie someone who has cancer is missed)\n",
    "In this case use Recall for measure.\n",
    "We can also use F1 to get a more balanced measure of Precision and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = (27,27,3)\n",
    "HIDDEN_LAYER_DIM = 256\n",
    "OUTPUT_CLASSES = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline an simple MLP Model\n",
    "Observations\n",
    "* Use a initial NN to get a baseline\n",
    "* Binary classification problem\n",
    "* Input has 2187 dims\n",
    "* 1 hidden layer with 256 internal nodes\n",
    "* 1 output binary\n",
    "* Loss - Binary Cross Entropy\n",
    "* Metric - binary_accuracy \n",
    "* use sigmoid activation as this is a logistics issue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model_base = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES,activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 2187)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               560128    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 560,385\n",
      "Trainable params: 560,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_base.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:17:53\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "history_base = model_base.fit(train_generator, validation_data = validation_generator, epochs=150, verbose=0)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"Took = \", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_y = testData['isCancerous'].astype('int')\n",
    "\n",
    "pred_y_base = model_base.predict(test_generator, batch_size=64, verbose=1)\n",
    "pred_y_base = np.argmax(pred_y_base, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y_base, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* Train vs Validation approaches at 150 epocs\n",
    "* There looks to be some overfitting\n",
    "* Recall is good (?) maybe too good \n",
    "* Precision low low at 0.40\n",
    "* F1 score low at 0.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use default lambda - note for assignment only. In real this might be in loop to determine best value.\n",
    "reg_lambda = 0.01\n",
    "\n",
    "model_reg = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_reg.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "history_reg = model_reg.fit(train_generator, validation_data = validation_generator, epochs=100, verbose=0)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"Took = \", datetime.datetime.now() - now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y_reg = model_reg.predict(test_generator, batch_size=64, verbose=1)\n",
    "pred_y_reg = np.argmax(pred_y_reg, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y_reg, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_lambda = 0.01\n",
    "\n",
    "model_drop = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Dense(HIDDEN_LAYER_DIM, activation='sigmoid'),\n",
    "    tf.keras.layers.Dropout(.3),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_drop.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "history_drop = model_drop.fit(train_generator, validation_data = validation_generator, epochs=150, verbose=0)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"Took = \", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also improves but test data looks to be better than training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y_drop = model_drop.predict(test_generator, batch_size=64, verbose=1)\n",
    "pred_y_drop = np.argmax(pred_y_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Plus VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_1 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 3\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Dense(\n",
    "        OUTPUT_CLASSES, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(reg_lambda),\n",
    "        activation='sigmoid' )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_1.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "history_VGG_1 = model_VGG_1.fit(train_generator, validation_data = validation_generator, epochs=100, verbose=0)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"Took = \", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_VGG_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y_vgg1 = model_VGG_1.predict(test_generator, batch_size=64, verbose=1)\n",
    "pred_y_vgg1 = np.argmax(pred_y_vgg1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y_vgg1, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y_vgg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 2\n",
    "Observations\n",
    "\n",
    "Issue is over fitting \n",
    "* We have 20k images so that should be ok for training\n",
    "* image size is small so down scaling is not too beneficial\n",
    "* after 40 epics so could stop early \n",
    "* over fitting so reduce the number of convolutions\n",
    "* Given number of images, data augmentation probably not required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_2 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(\n",
    "        OUTPUT_CLASSES, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(reg_lambda),\n",
    "        activation='sigmoid' )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_2.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "history_VGG_2 = model_VGG_2.fit(train_generator, validation_data = validation_generator, epochs=50, verbose=0)\n",
    "\n",
    "print(datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"Took = \", datetime.datetime.now() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_VGG_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y_vgg2 = model_VGG_2.predict(test_generator, batch_size=64, verbose=1)\n",
    "pred_y_vgg2 = np.argmax(pred_y_vgg2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_y, pred_y_vgg2, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y_vgg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCS2673 Assignment 2 P1A - Is or is not cancer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "#with zipfile.ZipFile('./Image_classification_data.zip', 'r') as zip_ref:\n",
    "#   zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "Split data into train, validation, and test\n",
    "Note that images for the same patient may contain a mix of cancerous and non-cancerous data.\n",
    "Q - Sould we split on patient or just randomly\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData = pd.read_csv('./data_labels_mainData.csv')\n",
    "extraData = pd.read_csv('./data_labels_extraData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>patientID</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>cellTypeName</th>\n",
       "      <th>cellType</th>\n",
       "      <th>isCancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22405</td>\n",
       "      <td>1</td>\n",
       "      <td>22405.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22406</td>\n",
       "      <td>1</td>\n",
       "      <td>22406.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22407</td>\n",
       "      <td>1</td>\n",
       "      <td>22407.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22408</td>\n",
       "      <td>1</td>\n",
       "      <td>22408.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22409</td>\n",
       "      <td>1</td>\n",
       "      <td>22409.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InstanceID  patientID  ImageName cellTypeName  cellType  isCancerous\n",
       "0       22405          1  22405.png   fibroblast         0            0\n",
       "1       22406          1  22406.png   fibroblast         0            0\n",
       "2       22407          1  22407.png   fibroblast         0            0\n",
       "3       22408          1  22408.png   fibroblast         0            0\n",
       "4       22409          1  22409.png   fibroblast         0            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>patientID</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>isCancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12681</td>\n",
       "      <td>61</td>\n",
       "      <td>12681.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12682</td>\n",
       "      <td>61</td>\n",
       "      <td>12682.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12683</td>\n",
       "      <td>61</td>\n",
       "      <td>12683.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12684</td>\n",
       "      <td>61</td>\n",
       "      <td>12684.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12685</td>\n",
       "      <td>61</td>\n",
       "      <td>12685.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InstanceID  patientID  ImageName  isCancerous\n",
       "0       12681         61  12681.png            0\n",
       "1       12682         61  12682.png            0\n",
       "2       12683         61  12683.png            0\n",
       "3       12684         61  12684.png            0\n",
       "4       12685         61  12685.png            0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratary Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstanceID       int64\n",
      "patientID        int64\n",
      "ImageName       object\n",
      "cellTypeName    object\n",
      "cellType         int64\n",
      "isCancerous      int64\n",
      "dtype: object\n",
      "(9896, 6)\n"
     ]
    }
   ],
   "source": [
    "print(mainData.dtypes)\n",
    "print(mainData.shape)\n",
    "#print(mainData.info())\n",
    "#print(mainData.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstanceID      int64\n",
      "patientID       int64\n",
      "ImageName      object\n",
      "isCancerous     int64\n",
      "dtype: object\n",
      "(10384, 4)\n"
     ]
    }
   ],
   "source": [
    "print(extraData.dtypes)\n",
    "print(extraData.shape)\n",
    "#print(extraData.info())\n",
    "#print(extraData.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 data files mainData with 6 properties and 9896 rows, and extraData with 4 properties and 10384 rows.\n",
    "\n",
    "For part1, the aim is to predict if a slide is cancerous or not from the image data.\n",
    "Lets append data and confirm the number of images matches the input data rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData = mainData.append(extraData, ignore_index=True)\n",
    "#mainData = mainData.sample(2000)   # Sampling used for inital model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20280"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainData.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20280\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "image_list = set()\n",
    "for filepath in glob.glob('./patch_images/*', recursive=True): #assuming gif\n",
    "    filename = filepath.split(\"\\\\\")[-1]\n",
    "    image_list.add(filename)\n",
    "    \n",
    "print(len(image_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of images matches the records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Categorical Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData['cellType'] = mainData['cellType'].astype('category')\n",
    "mainData['cellTypeName'] = mainData['cellTypeName'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InstanceID          0\n",
       "patientID           0\n",
       "ImageName           0\n",
       "cellTypeName    10384\n",
       "cellType        10384\n",
       "isCancerous         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79    699\n",
       "77    696\n",
       "91    642\n",
       "92    571\n",
       "80    507\n",
       "     ... \n",
       "75     12\n",
       "73     12\n",
       "35     11\n",
       "74      8\n",
       "96      6\n",
       "Name: patientID, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainData['patientID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mainData.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove non-relevant data - instance is ID\n",
    "mainData.drop(['InstanceID'], axis=1,inplace=True)\n",
    "\n",
    "# cellType and cellTypeName may be not known in scan so for this case removed - identification is part2\n",
    "# Note this data could be use but it is not as its not in main data set\n",
    "mainData.drop(['cellType'], axis=1,inplace=True)\n",
    "mainData.drop(['cellTypeName'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20280 entries, 0 to 20279\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   patientID    20280 non-null  int64 \n",
      " 1   ImageName    20280 non-null  object\n",
      " 2   isCancerous  20280 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 475.4+ KB\n"
     ]
    }
   ],
   "source": [
    "mainData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are no missing values in the datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def BinBreakdown(desc, data):\n",
    "    neg, pos = np.bincount(data)\n",
    "    total = neg + pos\n",
    "    print('{} Class Data:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(desc, total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Class Data:\n",
      "    Total: 20280\n",
      "    Positive: 7069 (34.86% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BinBreakdown('Input Data', mainData.isCancerous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key observations:\n",
    "* Data has 20280  observations and 6 columns.\n",
    "* InstanceID - is Id field, need to remove as not valueable classification attribute\n",
    "* cellTypeName, cellType - indicator of actual cell type and not used in this case for cancer diagnosis\n",
    "* isCancerous - indicator of the actual diagnosis (1 = cancerous, 0 = benign)\n",
    "* image count matches data rows\n",
    "* Patients have mix of images counts between 6 and 699 images per patient\n",
    "\n",
    "Split of benign to cancerous is a 35% cancerous, 65% benign\n",
    "\n",
    "* The class value is boolean so doesn't have outliers etc to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Split on Patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add classification class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mainData['isCancerous'] = mainData['isCancerous'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Validate/Test\n",
    "For test and training data split via person.\n",
    "This assumes that if a person has cancer or not, then would the images for that person have cancer.\n",
    "Also different cell types per person would be used for validation/testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get list of patients and observation counts\n",
    "# Allocate approc 25% of data for Validation and Testing - of that 60%/40% for validation/test split.\n",
    "TEST_RATIO = 0.10\n",
    "VAL_RATIO = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split train tests by ratios\n",
    "# Select random patients until the number of images for \n",
    "# each patient sums to the number of records require\n",
    "\n",
    "np.random.seed(43) # Consistent random list\n",
    "\n",
    "recCount = mainData.shape[0]\n",
    "custRec = mainData.patientID.value_counts().to_dict()\n",
    "    \n",
    "patientIds = list(custRec.keys())\n",
    "\n",
    "# Loop through selecting a patient at random summing the number of images they have\n",
    "# until the count of images crosses is more than required number\n",
    "\n",
    "testCust = []\n",
    "testRecs = 0\n",
    "while (testRecs < (recCount * TEST_RATIO)):\n",
    "    pId = np.random.choice(patientIds)\n",
    "    ic = custRec.get(pId)\n",
    "    patientIds.remove(pId)\n",
    "    testCust.append(pId)\n",
    "    testRecs += ic\n",
    "    \n",
    "#print(testCust, testRecs)\n",
    "\n",
    "valCust = []\n",
    "valRecs = 0\n",
    "while (valRecs < (recCount * VAL_RATIO)):\n",
    "    pId = np.random.choice(patientIds)\n",
    "    ic = custRec.get(pId)\n",
    "    patientIds.remove(pId)\n",
    "    valCust.append(pId)\n",
    "    valRecs += ic\n",
    "\n",
    "#print(valCust, valRecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData = mainData[mainData.patientID.isin(testCust)]\n",
    "valData = mainData[mainData.patientID.isin(valCust)]\n",
    "trainData = mainData[~(mainData.patientID.isin(valCust + testCust))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : 15054, Val Data: 3055, Test Data: 2171\n",
      "Train data : 74.23%, Val Data: 15.06%, Test Data: 10.71%\n"
     ]
    }
   ],
   "source": [
    "totalRecs = mainData.shape[0]\n",
    "#print(trainData.shape[0] + valData.shape[0] + testData.shape[0])\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(trainData.shape[0], valData.shape[0], testData.shape[0]))\n",
    "print(\"Train data : {:.2f}%, Val Data: {:.2f}%, Test Data: {:.2f}%\".format(\n",
    "    100 * trainData.shape[0] / totalRecs, 100 * valData.shape[0]/totalRecs, 100 * testData.shape[0]/totalRecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientID</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>isCancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>19035.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>19036.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>19037.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>19038.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>19039.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patientID  ImageName isCancerous\n",
       "19          2  19035.png           0\n",
       "20          2  19036.png           0\n",
       "21          2  19037.png           0\n",
       "22          2  19038.png           0\n",
       "23          2  19039.png           0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Class Data:\n",
      "    Total: 15054\n",
      "    Positive: 5264 (34.97% of total)\n",
      "\n",
      "Validation Class Data:\n",
      "    Total: 3055\n",
      "    Positive: 1096 (35.88% of total)\n",
      "\n",
      "Test Class Data:\n",
      "    Total: 2171\n",
      "    Positive: 709 (32.66% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BinBreakdown('Train', trainData.isCancerous)\n",
    "BinBreakdown('Validation', valData.isCancerous)\n",
    "BinBreakdown('Test', testData.isCancerous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tran/Val/Test data sets have unique patients with similar ratios of non-Cancerous to Cancerous images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1], <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(\n",
    "    trainData.isCancerous.value_counts().index.astype(str), \n",
    "    trainData.isCancerous.value_counts().values/np.sum(trainData.isCancerous.value_counts().values), \n",
    "    alpha=0.3, \n",
    "    color='r')\n",
    "\n",
    "plt.bar(\n",
    "    valData.isCancerous.value_counts().index.astype(str), \n",
    "    valData.isCancerous.value_counts().values/np.sum(valData.isCancerous.value_counts().values), \n",
    "    alpha=0.3, \n",
    "    color='b')\n",
    "\n",
    "plt.bar(\n",
    "    testData.isCancerous.value_counts().index.astype(str), \n",
    "    testData.isCancerous.value_counts().values/np.sum(testData.isCancerous.value_counts().values), \n",
    "    alpha=0.3, \n",
    "    color='g')\n",
    "\n",
    "plt.title('isCancerous - Train vs Test')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "1. Train/Validation/Test data distributions sets have similar distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images\n",
    "27x27 RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15054 validated image filenames belonging to 2 classes.\n",
      "Found 3055 validated image filenames belonging to 2 classes.\n",
      "Found 2171 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Could add Data Augmentation here - but initial trials showed no real improvement for a lot of extra traing time\n",
    "# Note: Sirinukunwattana 2016 and co arbitrary rotated patches (0, 90, 180, 270) and flipped them along vertical or \n",
    "# horizontal axis.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    data_format='channels_last',\n",
    "    #rotation_range=90, \n",
    "    #width_shift_range=0.1,\n",
    "    #height_shift_range=0.1, \n",
    "    #brightness_range=[0.5,1.5],\n",
    "    #horizontal_flip=True,\n",
    "    #vertical_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=trainData,\n",
    "        directory='./patch_images',\n",
    "        x_col=\"ImageName\",\n",
    "        y_col=\"isCancerous\",\n",
    "        target_size=(27, 27),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=valData,\n",
    "        directory='patch_images',\n",
    "        x_col=\"ImageName\",\n",
    "        y_col=\"isCancerous\",\n",
    "        target_size=(27, 27),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=testData,\n",
    "        directory='patch_images',\n",
    "        x_col=\"ImageName\",\n",
    "        y_col=\"isCancerous\",\n",
    "        target_size=(27, 27),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PlotModelFitHistory(mh):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(mh.history['loss'], 'r--')\n",
    "    plt.plot(mh.history['val_loss'], 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(mh.history['categorical_accuracy'], 'r--')\n",
    "    plt.plot(mh.history['val_categorical_accuracy'], 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def PlotConfusionMatrix(test, pred):\n",
    "    cm = confusion_matrix(test, pred)\n",
    "    group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sn.heatmap(cm, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure \n",
    "As this is a screening/detection task, the impact of a false negative is high (ie someone who has cancer is missed)\n",
    "In this case use Recall for measure.\n",
    "We can also use F1 to get a more balanced measure of Precision and Recall\n",
    "For training use accuracy of prediction as measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompileModel(model):\n",
    "    opt = tf.keras.optimizers.Adagrad()\n",
    "    model.compile(optimizer=opt,\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['categorical_accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using patience here - could use other limits\n",
    "early_stopping_patience=10\n",
    "early_stopping_monitor = EarlyStopping(patience=early_stopping_patience, monitor='val_categorical_accuracy')\n",
    "\n",
    "def FitModel(model):\n",
    "\n",
    "    print('start ', datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    fit_history = model.fit(train_generator, validation_data = validation_generator, \n",
    "                            callbacks=[early_stopping_monitor], epochs=10000, verbose=1)\n",
    "\n",
    "    print('stop ', datetime.datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    print(\"Took = \", datetime.datetime.now() - now)\n",
    "    \n",
    "    return fit_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictModel(model):\n",
    "    batch_size_ = 1\n",
    "    y_pred = list()\n",
    "    y_test = list()\n",
    "    filenames = test_generator.filenames\n",
    "    N_images = len(filenames)\n",
    "    batches = 0\n",
    "\n",
    "    # iterate through the data generator and predict for each batch\n",
    "    # hold the predictions and labels\n",
    "    for x,y in test_generator:\n",
    "            yp = model.predict(x, verbose=0)\n",
    "            yp = np.argmax(yp, axis = 1)\n",
    "            yt = np.argmax(y, axis = 1)\n",
    "            y_pred = y_pred + yp.tolist()\n",
    "            y_test = y_test + yt.tolist()\n",
    "\n",
    "            batches += 1\n",
    "            if batches >= N_images / batch_size_:\n",
    "                break\n",
    "                \n",
    "    return (y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelResult:\n",
    "  def __init__(self, name, accuracy, f1, precision, recall):\n",
    "    self.name = name\n",
    "    self.accuracy = accuracy\n",
    "    self.f1 = f1\n",
    "    self.precision = precision\n",
    "    self.recall = recall\n",
    "    \n",
    "modelResults = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowStats(test_name, y_test, y_pred):\n",
    "    accuracy = accuracy_score(test_y, pred_y)\n",
    "    f1 = f1_score(test_y, pred_y, average='macro')\n",
    "    cm = classification_report(test_y, pred_y, zero_division=0)\n",
    "    \n",
    "    prfs = precision_recall_fscore_support(test_y, pred_y, zero_division=0)\n",
    "    detect_precision = prfs[0][1]\n",
    "    detect_recall = prfs[1][1]\n",
    "\n",
    "    mr = ModelResult(test_name, accuracy, f1, detect_precision, detect_recall)\n",
    "    modelResults.append(mr)\n",
    "\n",
    "    print(\"Accuracy score: \", accuracy_score(test_y, pred_y))\n",
    "    print(\"F1 score: \", f1_score(test_y, pred_y, average='macro'))\n",
    "    print(classification_report(test_y, pred_y, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = (27,27,3)\n",
    "OUTPUT_CLASSES = 2       # TensorFlow automatically does one hot encoding to our target label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Baseline an simple MLP Model\n",
    "Observations\n",
    "* Use a initial NN to get a baseline\n",
    "* Binary classification problem - output are 2 variables OneHotEncoded\n",
    "* Input has 2187 dims (this is small for image recognition)\n",
    "* 1 hidden layer with 256 internal nodes\n",
    "* 2 output binary\n",
    "* Loss - Categorical Cross Entropy\n",
    "* Metric - categorical_accuracy \n",
    "* use sigmoid activation on last layer for probabilities as this is a logistics issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_base = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_base = FitModel(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('Baseline', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* Train vs Validation loss shows over fitting\n",
    "* Instability in accuracy could indicate too high learning rate\n",
    "* Results show low detection of cancorous images - recall at 66%\n",
    "* Model not predicting well and is overfitting - so try regularisation or dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Base Model with regularisation\n",
    "To reduce overfitting try regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use default lambda - note for assignment only. In real this might be in loop to determine best value.\n",
    "reg_lambda = 0.01\n",
    "\n",
    "model_reg = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_reg = FitModel(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('Base Reg', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* Loss vs Epochs plot shows significantly improved fitting\n",
    "* Accuracy stablises at ~ 82% after 20 epochs\n",
    "* Learning rate maybe still high but results good\n",
    "* Model positive case detection recall still low at 63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Base Model with dropout\n",
    "To reduce overfitting and improve speed see if minor drop out improves the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_drop = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_drop = FitModel(model_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('Base Drop', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* Loss vs Epochs plot shows significantly improved fitting\n",
    "* Accuracy stablises quicker than regularisation at ~ 85% after 10 or so epochs\n",
    "* Learning rate maybe still high but results good\n",
    "* Model positive case detection recall still improved at low at 72%\n",
    "* An improvement on regularisation\n",
    "\n",
    "Try convolution based on this model to get improve recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Plus VGG\n",
    "* Using an initial set of convolution layers may improve input to the MLP layers\n",
    "* Use standard VGG architecture to check if this provides better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_1 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 3\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid' )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_VGG_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_VGG_1 = FitModel(model_VGG_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_VGG_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_VGG_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('VGG1', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* Some overfitting - Model doesn't appear to reduce after 25 or so epochs\n",
    "* This model took much longer to train.\n",
    "* Reviewing the input size that VGG was designed for the number of inputs is much reduced.\n",
    "* Lets reduce the number of convolutions layers and converlutions in the layer to improve training times.\n",
    "* Detection recall slightly improved at 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VGG 2 with simplified convolutions\n",
    "* We have 20k images so that should be ok for training\n",
    "* image size is small so down scaling is not too beneficial\n",
    "* after 40 to 50 epics so could stop early \n",
    "* over fitting so reduce the number of convolutions\n",
    "* Given number of images, data augmentation probably not required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_VGG_2 = tf.keras.Sequential([\n",
    "    #VGG block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    #VGG block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid' )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_VGG_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_VGG_2 = FitModel(model_VGG_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_VGG_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_VGG_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('VGG2', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "* The model still took a long time to train\n",
    "* There looks to be some minimal overfitting\n",
    "* Reducing the number of epochs to 50 showed minimal loss issues but accuracy was jumbled\n",
    "* Detection recall still around 72%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SC-CNN 1\n",
    "* Try model based on SC-CNN \n",
    "* We have 20k images so that should be ok for training\n",
    "* The paper doesn't define last 2 layers of PARAMETER ESTIMATION (S1), AND SPATIALLY CONSTRAINED (S2) LAYERS.\n",
    "* This may be the key here but try without to see if the architecture works\n",
    "* Note 512 internal nodes and use of softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_SC_CNN_1 = tf.keras.Sequential([\n",
    "    # Convolution\n",
    "    \n",
    "    tf.keras.layers.Conv2D(24, (4, 4), activation='relu', padding='same', input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(36, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(512, activation='softmax'),\n",
    "    tf.keras.layers.Dense(OUTPUT_CLASSES, activation='sigmoid' )\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_SC_CNN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_SC_CNN_1 = FitModel(model_SC_CNN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_SC_CNN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_SC_CNN_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('SC-CNN 1', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "* The model overfitted slightly\n",
    "* Accuracy about same as VGG2\n",
    "* Detection Recall at 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. SC-CNN 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SC-CNN 1 adding some dropout to help reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_SC_CNN_2 = tf.keras.Sequential([\n",
    "    # Convolution\n",
    "    \n",
    "    tf.keras.layers.Conv2D(24, (4, 4), activation='relu', padding='same', input_shape=INPUT_DIM),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(36, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(512, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(reg_lambda)),\n",
    "      \n",
    "    tf.keras.layers.Dropout(.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(\n",
    "        OUTPUT_CLASSES, \n",
    "        kernel_regularizer=tf.keras.regularizers.l2(reg_lambda),\n",
    "        activation='sigmoid' )\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CompileModel(model_SC_CNN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_SC_CNN_2 = FitModel(model_SC_CNN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModelFitHistory(history_SC_CNN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_y, pred_y) = PredictModel(model_SC_CNN_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShowStats('SC-CNN 2', test_y, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotConfusionMatrix(test_y, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still didn't pickup anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison and ultimate judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print out Summary Results\n",
    "print(\"{:20} {:>10} {:>10} {:>10} {:>10}\".format('Name', 'Accuracy', 'F1-score', 'Precision', 'Recall'))\n",
    "for mr in modelResults:\n",
    "    print(\"{:20} {:10.2f} {:10.2f} {:10.2f} {:10.2f}\".format(mr.name, mr.accuracy, mr.f1, mr.precision, mr.recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base MLP model show overfitting\n",
    "Using Regularistion resulted in a better model\n",
    "Applying dropout also reduced overfitting but not the the same extent as regularisation \n",
    "\n",
    "Using the base VGG achitecture resulted in a small amount of overfitting\n",
    "As the size of the inputs are quite low reducing the number of convolutions and adding some regulariation in the final MLP \n",
    "latyer might create a better model. \n",
    "\n",
    "All base models showed good results with 100% recall\n",
    "Given the training time and simplicity the MLP with regularisation would be the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "* Results are the same for all models - looks bad but I can work out why\n",
    "* accuracy jumps around but how to set learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
